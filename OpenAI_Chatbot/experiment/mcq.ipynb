{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e1de8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "dee17eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\anubh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d55258b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\anubh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b0fa0f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\anubh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_community -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "29439524",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ec16878e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv() # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ef936ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key is set.\n"
     ]
    }
   ],
   "source": [
    "KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not KEY:\n",
    "    raise ValueError(\"Please set the OPENAI_API_KEY environment variable.\")\n",
    "else :\n",
    "    print(\"API Key is set.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df9fc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "llm=ChatOpenAI(openai_api_key=KEY,model_name=\"gpt-3.5-turbo\", temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a215ee98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0.1 -> 25.1.1\n",
      "[notice] To update, run: C:\\Users\\anubh\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv streamlit PyPDF2 -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "b0179177",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f0a9ad",
   "metadata": {},
   "source": [
    "Designing the Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "1d0828b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "RESPONSE_JSON = {\n",
    "    \"questions\": [\n",
    "        {\n",
    "            \"question\": \"What is the capital of France?\",\n",
    "            \"options\": [\"A) Paris\", \"B) London\", \"C) Berlin\", \"D) Madrid\"],\n",
    "            \"answer\": \"A\"\n",
    "        },\n",
    "        {\n",
    "            \"question\": \"What is the largest planet in our solar system?\",\n",
    "            \"options\": [\"A) Earth\", \"B) Jupiter\", \"C) Saturn\", \"D) Mars\"],\n",
    "            \"answer\": \"B\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8b3acacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE = \"\"\"\n",
    "You are an expert educator with deep knowledge in {topic} at a {level} level.\n",
    "You also understand human psychology and engagement design, enabling you to create fun, thought-provoking quizzes.\n",
    "\n",
    "Your task is to generate exactly {number_of_questions} quiz questions based on the following source material:\n",
    "\"{text}\". Make sure to cover key concepts from the text and the questions should vary in structure (e.g., multiple choice, true/false, fill-in-the-blank), if appropriate.\n",
    "The questions should not be repeatable and should be designed to test understanding of the material.\n",
    "\n",
    "### Requirements:\n",
    "1. Match the tone: **{tone}**\n",
    "2. Match the difficulty: **{level}** level\n",
    "3. Ensure coverage of key concepts from the text.\n",
    "4. Include a clear explanation for each correct answer.\n",
    "5. Questions should vary in structure (e.g., multiple choice, true/false, fill-in-the-blank), if appropriate.\n",
    "\n",
    "### Format:\n",
    "Return the quiz in this exact JSON format:\n",
    "{response_json}\n",
    "\n",
    "Make sure the JSON is syntactically valid and structured precisely.\n",
    "Do not add any extra commentary outside the JSON.\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c1fa921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generator_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\",\"number_of_questions\",\"topic\",\"level\",\"tone\",\"response_json\"],\n",
    "    template = TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8655e8b",
   "metadata": {},
   "source": [
    "Chaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "1490663a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\noutput_key lets you control the key name for the chain's output in the result dictionary, making it easier to access the generated content.\\n\""
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_generator_prompt,\n",
    "    output_key=\"quiz\",\n",
    "    verbose=True\n",
    ")\n",
    "\"\"\"\n",
    "output_key lets you control the key name for the chain's output in the result dictionary, making it easier to access the generated content.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39469c35",
   "metadata": {},
   "source": [
    "Evaluating the generated quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "948fa9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to checck if the generated quiz is valid or not\n",
    "TEMPLATE2 = \"\"\"\n",
    "You are an expert English grammarian, cognitive learning specialist, and educational content editor.\n",
    "\n",
    "Your task is to review the following multiple-choice quiz designed for {topic} students.\n",
    "\n",
    "### Instructions:\n",
    "1. **Evaluate the overall language, tone, and complexity** of the quiz.\n",
    "2. **Assess if the questions align** with the cognitive and analytical level appropriate for {topic} students.\n",
    "3. **Keep the complexity analysis within 50 words.**\n",
    "4. If any questions are too hard, too easy, poorly worded, or misaligned:\n",
    "   - **Revise only those specific questions.**\n",
    "   - Adjust the tone and phrasing to better suit the target student's ability.\n",
    "   - Preserve the original structure (e.g., multiple-choice format).\n",
    "\n",
    "### Input Quiz:\n",
    "{quiz}\n",
    "\n",
    "### Output Format:\n",
    "- **Complexity Analysis (<= 50 words)**:\n",
    "  ...\n",
    "- **Updated Questions (if any)**:\n",
    "  ...\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "5ee69b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"quiz\", \"topic\"],\n",
    "    template=TEMPLATE2\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c7423c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain = LLMChain(\n",
    "    llm=llm,\n",
    "    prompt=quiz_eval_prompt,\n",
    "    output_key=\"review\",\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94c48b",
   "metadata": {},
   "source": [
    "Connecting the chains using sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2a850f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_eval_chain = SequentialChain(\n",
    "    chains=[quiz_chain, review_chain],\n",
    "    input_variables=[\"text\", \"number_of_questions\", \"topic\", \"level\", \"tone\", \"response_json\"],\n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f09303",
   "metadata": {},
   "source": [
    "Passing it data via a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "74331cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = r\"D:\\VS_Code_WorkSpaces\\GenAI\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "a2a590fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\VS_Code_WorkSpaces\\\\GenAI\\\\data.txt'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "fb6ade8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_path, 'r') as file:\n",
    "    data = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "4521fa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI automation refers to the use of Artificial Intelligence (AI) technologies to automate complex tasks and processes that typically require human intelligence. It goes beyond traditional rule-based automation (like Robotic Process Automation - RPA) by enabling systems to learn, adapt, and make informed decisions based on data.\n",
      "\n",
      "Key Aspects of AI Automation:\n",
      "Intelligent Decision-Making: AI automation leverages machine learning (ML) and deep learning to analyze data, identify patterns, and make more accurate predictions and decisions than traditional automation.\n",
      "Handling Unstructured Data: Unlike traditional automation, AI automation can handle unstructured data such as text, images, and audio, using technologies like Natural Language Processing (NLP) and computer vision.\n",
      "Continuous Learning: AI systems continuously learn and improve over time as they process new data, becoming more efficient and accurate.\n",
      "Scalability: AI automation can scale quickly to handle increasing volumes of work and complexity. \n",
      "Benefits of AI Automation:\n",
      "Increased Efficiency and Productivity: Automating tasks frees up employees to focus on higher-value, strategic work.\n",
      "Enhanced Decision-Making: AI-powered analysis provides data-driven insights for more informed and faster decision-making.\n",
      "Improved Accuracy: AI minimizes human error in repetitive tasks, leading to higher precision in various processes.\n",
      "Enhanced Customer Experience: AI enables personalized interactions and faster responses through tools like chatbots and virtual assistants.\n",
      "Cost Savings: Automating processes and improving efficiency can lead to significant cost reductions.\n",
      "Risk Mitigation: AI can help detect anomalies and potential fraud, enhancing security and compliance. \n",
      "Examples of AI Automation in Various Industries:\n",
      "Healthcare: AI assists in disease detection and diagnosis, streamlines administrative tasks, and helps personalize patient care.\n",
      "Finance: AI automates fraud detection, credit scoring, and compliance monitoring.\n",
      "Manufacturing: AI enhances quality control, predictive maintenance, and production scheduling.\n",
      "Retail: AI personalizes recommendations, optimizes inventory management, and improves the customer experience.\n",
      "Customer Service: AI-powered chatbots handle customer inquiries, offering instant and personalized support. \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "68909d31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"questions\": [{\"question\": \"What is the capital of France?\", \"options\": [\"A) Paris\", \"B) London\", \"C) Berlin\", \"D) Madrid\"], \"answer\": \"A\"}, {\"question\": \"What is the largest planet in our solar system?\", \"options\": [\"A) Earth\", \"B) Jupiter\", \"C) Saturn\", \"D) Mars\"], \"answer\": \"B\"}]}'"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#serializing the py dict into a json file\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb3912",
   "metadata": {},
   "source": [
    "LangChain callbacks are hooks or listeners that let you track and log what happens during the execution of LLM chains, tools, and agents.\n",
    "\n",
    "Think of them as a \"behind-the-scenes monitor\" that:\n",
    "\n",
    "Captures intermediate steps\n",
    "\n",
    "Measures token usage, cost, and latency\n",
    "\n",
    "Logs prompts and outputs\n",
    "\n",
    "Helps in debugging and optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "532d6c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert educator with deep knowledge in AI Automation at a intermediate level.\n",
      "You also understand human psychology and engagement design, enabling you to create fun, thought-provoking quizzes.\n",
      "\n",
      "Your task is to generate exactly 5 quiz questions based on the following source material:\n",
      "\"AI automation refers to the use of Artificial Intelligence (AI) technologies to automate complex tasks and processes that typically require human intelligence. It goes beyond traditional rule-based automation (like Robotic Process Automation - RPA) by enabling systems to learn, adapt, and make informed decisions based on data.\n",
      "\n",
      "Key Aspects of AI Automation:\n",
      "Intelligent Decision-Making: AI automation leverages machine learning (ML) and deep learning to analyze data, identify patterns, and make more accurate predictions and decisions than traditional automation.\n",
      "Handling Unstructured Data: Unlike traditional automation, AI automation can handle unstructured data such as text, images, and audio, using technologies like Natural Language Processing (NLP) and computer vision.\n",
      "Continuous Learning: AI systems continuously learn and improve over time as they process new data, becoming more efficient and accurate.\n",
      "Scalability: AI automation can scale quickly to handle increasing volumes of work and complexity. \n",
      "Benefits of AI Automation:\n",
      "Increased Efficiency and Productivity: Automating tasks frees up employees to focus on higher-value, strategic work.\n",
      "Enhanced Decision-Making: AI-powered analysis provides data-driven insights for more informed and faster decision-making.\n",
      "Improved Accuracy: AI minimizes human error in repetitive tasks, leading to higher precision in various processes.\n",
      "Enhanced Customer Experience: AI enables personalized interactions and faster responses through tools like chatbots and virtual assistants.\n",
      "Cost Savings: Automating processes and improving efficiency can lead to significant cost reductions.\n",
      "Risk Mitigation: AI can help detect anomalies and potential fraud, enhancing security and compliance. \n",
      "Examples of AI Automation in Various Industries:\n",
      "Healthcare: AI assists in disease detection and diagnosis, streamlines administrative tasks, and helps personalize patient care.\n",
      "Finance: AI automates fraud detection, credit scoring, and compliance monitoring.\n",
      "Manufacturing: AI enhances quality control, predictive maintenance, and production scheduling.\n",
      "Retail: AI personalizes recommendations, optimizes inventory management, and improves the customer experience.\n",
      "Customer Service: AI-powered chatbots handle customer inquiries, offering instant and personalized support. \". Make sure to cover key concepts from the text and the questions should vary in structure (e.g., multiple choice, true/false, fill-in-the-blank), if appropriate.\n",
      "The questions should not be repeatable and should be designed to test understanding of the material.\n",
      "\n",
      "### Requirements:\n",
      "1. Match the tone: **engaging and educational**\n",
      "2. Match the difficulty: **intermediate** level\n",
      "3. Ensure coverage of key concepts from the text.\n",
      "4. Include a clear explanation for each correct answer.\n",
      "5. Questions should vary in structure (e.g., multiple choice, true/false, fill-in-the-blank), if appropriate.\n",
      "\n",
      "### Format:\n",
      "Return the quiz in this exact JSON format:\n",
      "{\"questions\": [{\"question\": \"What is the capital of France?\", \"options\": [\"A) Paris\", \"B) London\", \"C) Berlin\", \"D) Madrid\"], \"answer\": \"A\"}, {\"question\": \"What is the largest planet in our solar system?\", \"options\": [\"A) Earth\", \"B) Jupiter\", \"C) Saturn\", \"D) Mars\"], \"answer\": \"B\"}]}\n",
      "\n",
      "Make sure the JSON is syntactically valid and structured precisely.\n",
      "Do not add any extra commentary outside the JSON.\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1*************************************************************ff7e. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Temp\\ipykernel_11332\\2110230405.py\", line 4, in <module>\n",
      "    response = generate_eval_chain.invoke({\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 167, in invoke\n",
      "    raise e\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 157, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\sequential.py\", line 107, in _call\n",
      "    outputs = chain(known_values, return_only_outputs=True, callbacks=callbacks)\n",
      "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\_api\\deprecation.py\", line 189, in warning_emitting_wrapper\n",
      "    return wrapped(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 386, in __call__\n",
      "    return self.invoke(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 167, in invoke\n",
      "    raise e\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\base.py\", line 157, in invoke\n",
      "    self._call(inputs, run_manager=run_manager)\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 127, in _call\n",
      "    response = self.generate([inputs], run_manager=run_manager)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain\\chains\\llm.py\", line 139, in generate\n",
      "    return self.llm.generate_prompt(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 957, in generate_prompt\n",
      "    return self.generate(prompt_messages, stop=stop, callbacks=callbacks, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 776, in generate\n",
      "    self._generate_with_cache(\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_core\\language_models\\chat_models.py\", line 1022, in _generate_with_cache\n",
      "    result = self._generate(\n",
      "             ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py\", line 476, in _generate\n",
      "    response = self.completion_with_retry(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\langchain_community\\chat_models\\openai.py\", line 387, in completion_with_retry\n",
      "    return self.client.create(**kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\_utils\\_utils.py\", line 287, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\resources\\chat\\completions\\completions.py\", line 1087, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\_base_client.py\", line 1249, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\anubh\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\openai\\_base_client.py\", line 1037, in request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.AuthenticationError: Error code: 401 - {'error': {'message': 'Incorrect API key provided: sk-or-v1*************************************************************ff7e. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "#to track token usage in langchain\n",
    "with get_openai_callback() as cb:\n",
    "    try:\n",
    "        response = generate_eval_chain.invoke({\n",
    "            \"text\": data,\n",
    "            \"number_of_questions\": 5,\n",
    "            \"topic\": \"AI Automation\",\n",
    "            \"level\": \"intermediate\",\n",
    "            \"tone\": \"engaging and educational\",\n",
    "            \"response_json\": json.dumps(RESPONSE_JSON)\n",
    "        })\n",
    "        print(\"Response:\", response)\n",
    "    except Exception as e:\n",
    "        print(\"An error occurred:\", e)\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ffbff7c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens Used: 0\n",
      "\tPrompt Tokens: 0\n",
      "\t\tPrompt Tokens Cached: 0\n",
      "\tCompletion Tokens: 0\n",
      "\t\tReasoning Tokens: 0\n",
      "Successful Requests: 0\n",
      "Total Cost (USD): $0.0\n"
     ]
    }
   ],
   "source": [
    "print(cb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d879ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = response.get('quiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8907379",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = json.loads(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0fb61",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in response_json.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})\n",
    "\n",
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24166cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d598c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"AIAutomation_quiz.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb477f5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'07_02_2025_15_47_49'"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime_str = datetime.now().strftime('%m_%d_%Y_%H_%M_%S')\n",
    "datetime_str #saving the file in the logger with the current date and time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
